Project Proposal: An ONOS-Based Northbound Application for
Adaptive Traffic Routing
Naga Bhuvith
Sriman Reddy
Pavan Deekshith
Dhiraj
Harshith Venigalla
October 16, 2025
1Executive Summary & Project Vision
1.1Project Statement
This proposal outlines a four-week project to develop and validate a Northbound Application for the
Open Network Operating System (ONOS) controller. The application, developed in Java, will implement
an adaptive routing algorithm that dynamically reconfigures network paths based on real-time link
utilization metrics. The project’s efficacy will be demonstrated within a Mininet-IP emulated network,
with performance quantitatively benchmarked against a standard static routing approach. The primary
objective is to produce a proof-of-concept that validates the tangible benefits of adaptive routing in
a Software-Defined Networking (SDN) environment, specifically in reducing congestion and improving
network throughput and latency.
1.2
Problem Domain and Strategic Value
Traditional network architectures are fundamentally static. They rely on routing protocols that estab-
lish fixed paths for data transmission, which are updated infrequently and are largely insensitive to the
dynamic, bursty nature of modern network traffic.[1, 2] This architectural rigidity often leads to subopti-
mal resource utilization, where some network links become heavily congested, causing increased latency
and packet loss, while alternative paths remain underutilized. This inefficiency directly degrades the
performance of applications and the overall Quality of Service (QoS) delivered to end-users.
Software-Defined Networking (SDN) presents a paradigm shift designed to overcome these limitations.
The core innovation of SDN is the physical and logical separation of the network’s control plane (which
makes routing decisions) from the data plane (which forwards packets).[3, 4] This decoupling centralizes
network intelligence into a software-based SDN controller, transforming the network into a programmable
platform.[2, 5, 6] This centralized programmability enables the development of sophisticated applications
that can monitor the network’s global state and dynamically manage traffic flow in an automated and
intelligent manner.[4, 7]
The strategic value of this project lies in its practical application of these SDN principles. By
developing an intelligent Northbound Application, this project will directly address the shortcomings
of static routing. The application will leverage the controller’s global network view to make real-time,
data-driven routing decisions, proactively steering traffic away from congested links and onto optimal
paths.[8, 9] The successful implementation of this system will serve as a powerful validation of SDN’s
core promise: the creation of agile, application-aware, and automated networks capable of maximizing
the efficiency of the underlying infrastructure and delivering superior performance.[1]
1.3
High-Level Objectives & Expected Outcomes
To achieve the project’s vision, the following high-level objectives have been defined:
• Objective 1: Design and implement a modular, Java-based ONOS application capable of peri-
odically monitoring and collecting port-level traffic statistics from all devices within the network
topology.
• Objective 2: Develop and integrate a dynamic, adaptive routing algorithm that utilizes the
collected statistics to calculate the least-congested path between any two endpoints in the network.
1• Objective 3: Construct a custom, multi-path network topology using the Mininet-IP emulator to
create a realistic and controllable environment for inducing and observing network congestion.
• Objective 4: Conduct a rigorous, data-driven performance evaluation by comparing the adaptive
routing application against a baseline static routing implementation under identical, reproducible
traffic loads.
The principal expected outcome of this project is a fully functional proof-of-concept system, com-
prising the ONOS application and the Mininet-IP testing environment. This will be accompanied by a
comprehensive final report that empirically demonstrates, through quantitative analysis, that the adap-
tive routing solution successfully mitigates network congestion and achieves a significant, measurable
improvement in key performance metrics—namely, aggregate throughput and end-to-end latency—when
compared to the static routing baseline.
2System Architecture and Technology Stack
2.1Foundational SDN Principles
The architecture of the proposed system is fundamentally grounded in the core principles of Software-
Defined Networking. The design explicitly leverages the separation of the control and data planes, a
defining characteristic of SDN that enables network control to become directly programmable.[2, 3, 4]
The system is structured according to the three-layer SDN model:
1. Infrastructure Layer (Data Plane): This layer consists of the network forwarding devices, in
this case, virtual OpenFlow switches emulated by Mininet. These devices are responsible for the
actual forwarding of data packets based on flow rules programmed by the control layer.[5, 6]
2. Control Layer: This layer is embodied by the ONOS SDN controller. It acts as the centralized
”brain” of the network, maintaining a global view of the topology and state. It communicates with
the data plane via a southbound interface (OpenFlow) to install forwarding rules and with the
application layer via a northbound interface (Java APIs) to receive instructions.[3, 5]
3. Application Layer: This is where the custom Adaptive Routing Application resides. It contains
the business logic for monitoring the network and making intelligent routing decisions. The appli-
cation communicates its requirements to the ONOS controller through its well-defined Northbound
APIs, abstracting the complexities of the underlying network hardware.[2, 6]
2.2
Component Overview and Interaction
The system comprises three primary, interacting components, each fulfilling a distinct role within the
SDN architecture:
• Mininet-IP Emulation Environment: This component serves as the data plane. It will be
configured with a custom topology of virtual OpenFlow-enabled switches, hosts, and capacity-
constrained links. Its sole responsibility is to process and forward packets according to the flow
rules present in the switches’ flow tables.[10, 11] The switches are configured to connect to the
ONOS controller, ceding all control logic to it.[12]
• ONOS SDN Controller: This component is the control plane. ONOS maintains a real-time,
global network graph by discovering devices, links, and hosts through its southbound providers.[13,
14] It exposes this comprehensive network view and a rich set of control services (e.g., topology
information, flow rule programming) to northbound applications via its Java APIs.[15, 16]
• Adaptive Routing Application: This component represents the application plane logic. It is a
custom Java application deployed and executed within the ONOS Karaf container. The applica-
tion’s operational flow is cyclical:
1. It queries ONOS core services via the Northbound API to retrieve network topology and port
statistics.
2. It processes this data to calculate real-time link utilization.
23. It executes its internal adaptive routing algorithm to determine the optimal, least-congested
path for traffic flows.
4. It instructs ONOS, again via the Northbound API, to install the necessary OpenFlow rules
onto the data plane switches to enforce the calculated path.[17]
2.3
Technology Stack Justification
The selection of technologies for this project is based on their suitability for creating a robust, high-
performance, and realistic SDN proof-of-concept.
• ONOS (Open Network Operating System): ONOS is selected as the SDN controller due
to its design for carrier-grade environments, which emphasizes high availability, performance, and
scalability.[15, 18] Its distributed core architecture ensures resilience against controller failures, a
critical feature for production networks.[13, 14] Furthermore, ONOS provides a powerful, modular
software platform with extensive and well-documented Java-based Northbound APIs, which greatly
simplifies and accelerates the development of complex network control applications.[19, 20]
• Java: As the native development language for ONOS applications, Java is the logical choice for
this project.[16] Its use ensures seamless and efficient integration with the ONOS core services and
allows the project to leverage the mature, robust, and extensive Java development ecosystem for
building, testing, and dependency management.
• Mininet-IP: Mininet is a highly effective and widely used network emulator that allows for the
creation of realistic, virtual network topologies on a single machine.[10] The Mininet-IP extension
is specifically chosen for its enhanced support for IP-based routing scenarios.[12] This provides
a flexible, low-cost, and highly controllable environment essential for rapid prototyping, develop-
ment, and rigorous validation of the routing application without the expense and complexity of
physical network hardware.[13, 21] It allows for the precise definition of network topologies and link
characteristics (e.g., bandwidth), which is critical for creating reproducible congestion scenarios.[22]
The architecture of this system demonstrates a powerful synergy between the requirements of adap-
tive routing and the capabilities afforded by SDN. Adaptive routing algorithms, by their nature, function
most effectively when they can make decisions based on a global, real-time view of the network’s state,
including its topology and traffic load distribution.[9, 23] In traditional, distributed networking environ-
ments, acquiring such a global view is a slow, complex, and overhead-intensive process, as individual
routers must exchange state information through protocol messages, leading to a fragmented and often
stale understanding of the network.[1] The SDN architecture fundamentally solves this problem. The
controller, by design, centralizes this intelligence and is responsible for maintaining a comprehensive and
up-to-date network information base.[2, 4] The ONOS controller, in particular, excels at this, providing
applications with programmatic access to a consistent, global network graph.[13, 14] This allows the
adaptive routing application to query the ONOS core and receive an instantaneous, accurate snapshot
of the entire network, enabling it to compute truly optimal paths with an efficiency and timeliness that
is simply unattainable in traditional architectures.
Furthermore, the selection of ONOS as the controller platform is a strategic decision that underpins
the project’s focus on creating a solution with real-world applicability. The research literature and
community consistently refer to ONOS as ”carrier-grade,” a designation that reflects its architectural
design for high availability, massive scalability, and high-performance event processing.[15, 18, 19, 20]
Its distributed core provides inherent fault tolerance, and its subsystems are optimized for low-latency
operations.[14, 24] By building the application on this robust foundation, the project ensures that the
controller itself will not become a performance bottleneck. This is critical for a real-time adaptive routing
system, which depends on the controller’s ability to reliably process network events and deliver flow rule
updates to the data plane with minimal delay.
3
Adaptive Routing Application Design & Implementation
The Adaptive Routing Application will be a self-contained ONOS application, implemented in Java and
structured into three distinct, cooperative modules.
33.1
Module 1: Network State Monitoring
The primary objective of this module is to periodically collect raw traffic statistics from the data plane
and transform them into a meaningful metric of link utilization. This provides the foundational data
upon which all routing decisions are based.
The implementation will feature a dedicated thread managed by a ScheduledExecutorService. This
thread will be configured to execute its data collection task at a regular, configurable interval (e.g., every
5 seconds). During each execution cycle, the thread will perform the following steps:
1. Obtain a reference to the core ONOS DeviceService.
2. Use the deviceService.getAvailableDevices() method to retrieve an iterable collection of all
currently active network switches.[25, 26]
3. For each Device in the collection, it will invoke deviceService.getPortStatistics(device.id())
to fetch a list of PortStatistics objects for all ports on that switch.[25, 26]
4. Each PortStatistics object contains cumulative counters, such as bytesSent() and bytesReceived().
The module will maintain a local cache of the previous reading for each port. By subtracting the
previous reading from the current one and dividing by the polling interval, it will calculate the
average data rate (in bytes per second) for that port over the last interval.
5. This calculated data rate will then be used to determine the link utilization. The capacity of each
link will be a configurable parameter, reflecting the bandwidth set in the Mininet topology. The
utilization U (L) for a link L connected to the port will be calculated as (current rate * 8) /
link capacity bps.
6. The resulting utilization values (as a percentage or fraction) will be stored in a thread-safe data
structure, such as a ConcurrentHashMap, which maps each Link object in the topology to its most
recently calculated utilization.
3.2
Module 2: Adaptive Routing Algorithm
This module constitutes the core intelligence of the application. Its objective is to compute the optimal
(least-cost) path between any two hosts in the network, where the definition of ”cost” is dynamically
influenced by network congestion.
A modified version of Dijkstra’s shortest path algorithm will be implemented for this purpose. While
Dijkstra’s is a standard algorithm, its application here is novel due to the dynamic calculation of link
weights, which serves as the cost function.[23] The weight W of any given link L in the network graph
will be determined by the following formula:
W (L) = α · H + β · U (L)
Where:
• H is the static hop cost, a constant value (e.g., 1). This component ensures that, all other factors
being equal, the algorithm prefers paths with fewer hops.
• U (L) is the real-time link utilization (e.g., a value from 0.0 to 1.0) for link L, as calculated and
provided by the Network State Monitoring module. This component heavily penalizes congested
links, making them ”heavier” and thus less desirable.
• α and β are configurable weighting factors that allow for tuning the algorithm’s behavior. A high
β value relative to α will make the algorithm aggressively avoid any link with even moderate
utilization, prioritizing low congestion over hop count. Conversely, a high α will make it behave
more like a traditional shortest-path algorithm.
The implementation will be triggered when a new flow that requires a path is detected (e.g., via an
ONOS PacketIn event). The module will then:
1. Access the TopologyService to get the current TopologyGraph.
2. Construct a new, temporary weighted graph representation based on the ONOS topology.
43. Iterate through every link in the topology, calculating its weight W (L) using the formula above
and the most recent utilization data from Module 1.
4. Execute Dijkstra’s algorithm on this dynamically weighted graph to find the path with the minimum
total weight between the source and destination hosts. This approach directly fulfills the project
goal of finding paths that intelligently circumvent network congestion.[8, 27, 28]
3.3
Module 3: Dynamic Flow Provisioning
This module is responsible for translating the abstract optimal path computed by the routing algorithm
into concrete, device-specific forwarding rules and installing them onto the data plane switches.
The implementation will rely on the ONOS FlowRuleService, which provides a powerful, low-level
Northbound API for the direct programming of device flow tables.[16, 29, 30] Once the routing algorithm
provides an optimal path (represented as an ordered list of links), this module will:
1. Iterate through each link in the path. Each link connects an ingress switch to an egress switch.
2. For each switch along the path, it will construct a FlowRule object using the DefaultFlowRule.builder()
pattern.[31]
3. The FlowRule will be configured with the following components:
• TrafficSelector: A TrafficSelector will be built to match the specific flow. At a minimum,
this will match on the ETH TYPE (IPv4), IPV4 SRC (source host IP), and IPV4 DST (destination
host IP).
• TrafficTreatment: A TrafficTreatment will be built to define the action. The primary
action will be OUTPUT to the specific PortNumber that corresponds to the egress link for that
hop in the path.
• Priority: A suitable priority level will be assigned to the flow rule to ensure it is evaluated
correctly relative to other rules in the flow table.
• Timeout: An idle or hard timeout can be set. This is a crucial parameter, as it determines
how long the flow rule remains on the switch. An idle timeout will cause the rule to be
removed if no traffic matches it for a period, forcing a re-computation of the path when the
flow resumes.
4. The fully constructed FlowRule object will be passed to the flowRuleService.applyFlowRules()
method, which instructs ONOS to push the rule down to the corresponding switch via Open-
Flow.[29, 32] This proactive installation ensures that once the path is established, subsequent
packets of the flow are forwarded at line rate by the hardware, without requiring further interven-
tion from the controller.
A critical design decision in this project is the deliberate use of the low-level FlowRuleService API
instead of ONOS’s higher-level Intent Framework. This choice is necessitated by the core requirements
of the project. The Intent Framework is a powerful abstraction that allows an application to declare
its desired network state or policy—the ”what” (e.g., provide connectivity between Host A and Host
B)—while leaving the implementation details—the ”how” (i.e., the specific path computation and flow
rule installation)—to the ONOS core.[33, 34] Using the Intent Framework would effectively delegate the
very routing logic that this project is tasked with creating. In contrast, the FlowRuleService provides
direct, granular, and explicit control over the forwarding rules in the data plane.[29, 32] It allows the
application to act as the authoritative source for pathing decisions. While this approach is more complex
and places greater responsibility on the application for tasks like loop avoidance and rule consistency,
it is the only way to faithfully implement and validate a custom routing algorithm, thus making it the
correct choice for achieving the project’s objectives.
The three modules together form a closed-loop, adaptive control system. This continuous Monitor ->
Calculate -> Provision cycle is the essence of the system’s dynamic behavior. Traffic is provisioned
onto a path (Module 3), the impact of this traffic on link utilization is observed (Module 1), and this
new state information is fed back into the routing algorithm’s cost function (Module 2). If a flow
begins to cause congestion, the utilization term U (L) for the links in its path will increase, raising their
calculated weight W (L). During the next path computation cycle, the algorithm will naturally identify
an alternative, less-congested path as having a lower total cost. Module 3 will then install new flow
rules to reroute the traffic, thus completing the feedback loop and adaptively responding to the changing
network conditions.
54
Emulation and Validation Environment
A carefully designed and controlled emulation environment is paramount for the rigorous validation of
the adaptive routing application. This environment will be constructed using Mininet-IP to provide a
realistic yet fully manageable network testbed.
4.1
Custom Mininet-IP Network Topology
A custom network topology will be implemented to create a scenario that is simple enough for clear
analysis yet complex enough to demonstrate the value of adaptive routing.
• Topology Design: A ”diamond” topology will be created. This topology consists of four switches
(s1, s2, s3, s4) and two hosts (h1, h2). The source host, h1, is connected to switch s1, and the
destination host, h2, is connected to switch s4. Crucially, there are two distinct, parallel paths
between s1 and s4:
– Path A: s1 -> s2 -> s4
– Path B: s1 -> s3 -> s4
• Rationale: This topology is intentionally chosen because it provides a clear, binary routing choice.
For any traffic flowing from h1 to h2, the control application must decide whether to use Path A
or Path B. This simple yet effective design allows for the creation of an unambiguous congestion
scenario. By generating traffic that exceeds the capacity of one path, the system is forced to make
a decision, and the outcome of that decision can be clearly observed and measured.
• Implementation: The topology will be defined in a custom Python script utilizing the Mininet
API.[12, 21] Within this script, the addLink() method will be used with parameters to explicitly
set the bandwidth of the links (e.g., 10 Mbps). This is essential for creating predictable and
reproducible congestion. The script will also instantiate a RemoteController object, pointing
to the IP address and port of the running ONOS instance, ensuring that all virtual switches
automatically connect to the controller upon startup.[11, 35, 36]
4.2
Traffic Generation Scenarios
To perform a comparative analysis, two distinct scenarios will be executed using identical traffic patterns.
The iperf network performance tool will be used within the Mininet environment to generate traffic
and measure key metrics like throughput and packet loss.[37, 38]
• Scenario 1: Baseline (Static Routing):
1. The custom adaptive routing application will be deactivated in ONOS.
2. The standard ONOS reactive forwarding application (org.onosproject.fwd) will be acti-
vated. This application implements a simple, static shortest-path routing logic.
3. An iperf server will be started on the destination host (h2).
4. A high-bandwidth iperf TCP flow (the ”congestion flow”) will be initiated from h1 to h2
with a target bandwidth designed to saturate one of the 10 Mbps paths (e.g., iperf -c h2
-t 60 -b 15M).
5. Concurrently, a second, low-bandwidth iperf UDP flow (the ”probe flow”) will be run between
h1 and h2 to measure jitter and packet loss, and the ping utility will be used to measure
latency.
6. Performance metrics (throughput, latency, loss) will be recorded from the iperf and ping
outputs.
• Scenario 2: Adaptive Routing:
1. The environment will be reset. The standard forwarding application will be deactivated, and
the custom adaptive routing application will be activated.
2. The exact same sequence of iperf and ping commands from Scenario 1 will be executed.
63. The application’s behavior and the resulting network performance will be closely monitored.
The expected behavior is that the application will initially route the congestion flow down one
path (e.g., Path A). As the monitoring module detects high utilization on the links of Path A,
the routing algorithm will recalculate the optimal path to be Path B. The flow provisioning
module will then install new rules to reroute the traffic.
4. Performance metrics will be recorded for direct comparison with the baseline scenario.
The design of this validation environment constitutes a falsifiable experiment, which is a cornerstone
of sound scientific and engineering methodology. The diamond topology creates a controlled environment
with a clear, binary choice, eliminating ambiguity in the routing decision. The traffic generation sce-
nario is specifically engineered to introduce a problem—congestion on a primary path—that the adaptive
application is hypothesized to solve. The static routing baseline is expected to perform poorly under
this test, as it will lack the intelligence to recognize and react to the congestion, leading to high packet
loss and degraded throughput. By executing an identical test against the adaptive application, a direct,
A/B comparison of the outcomes is possible. If the adaptive application successfully reroutes traffic and
demonstrates superior performance metrics, the hypothesis is supported. If it fails to do so, the hypoth-
esis is falsified. This rigorous experimental structure is critical for producing a valid and meaningful
conclusion about the application’s efficacy.
5
Performance Evaluation Framework and Success Criteria
A formal framework for performance evaluation is essential to objectively assess the project’s outcome.
This framework defines the precise experimental procedure, the key metrics to be measured, and the
quantitative criteria for success.
5.1
Experimental Procedure
The performance evaluation will be conducted through a systematic and repeatable procedure:
1. Setup: Deploy the ONOS controller. Launch the Mininet-IP environment using the custom di-
amond topology script, ensuring all virtual switches successfully connect to the ONOS instance.
Verify initial network connectivity between all hosts using pingall.
2. Baseline Run: In ONOS, ensure the custom application is deactivated and activate the standard
reactive forwarding application (org.onosproject.fwd). Execute the traffic generation scenario as
defined in Section 4.2. This entire test run (from traffic start to finish) will be repeated 5 times to
account for any minor variations and to ensure the results are statistically significant. The output
from iperf and ping for each of the 5 runs will be logged to separate files.
3. Adaptive Run: Reset the entire environment by restarting both ONOS and Mininet to ensure a
clean state. In ONOS, activate the custom adaptive routing application and ensure the standard
forwarding application is deactivated. Execute the identical traffic generation scenario from the
baseline run. This test will also be repeated 5 times, with all output data logged.
4. Data Analysis: Aggregate the logged results from all 10 runs (5 baseline, 5 adaptive). For each
performance metric, calculate the mean and standard deviation across the 5 runs for both the static
and adaptive scenarios.
5. Reporting: Present the analyzed data clearly using tables and graphs. The final report will
compare the performance of the two approaches, explicitly referencing the success criteria defined
below to draw a definitive conclusion.
5.2
Key Performance Indicators (KPIs)
The following KPIs will be measured to provide a comprehensive assessment of network performance:
• Aggregate Throughput (Mbps): Measured using the iperf TCP test. This is the primary
indicator of the network’s ability to effectively utilize its available capacity. A higher value indicates
better performance.
7• End-to-End Latency (ms): Measured using the round-trip time (RTT) reported by the ping
utility, running concurrently with the iperf tests. This metric is a critical indicator of QoS,
reflecting the delay experienced by packets. A lower value is better.
• Packet Loss Rate (%): Measured by iperf during the UDP probe flow. This directly quantifies
the severity of network congestion, as switches will drop packets when their buffers overflow. A
lower value is better.
• Rerouting Time (ms): This metric is specific to the adaptive application. It will be measured
by instrumenting the application code with logging statements that timestamp (a) the moment
a congestion threshold is breached and a recalculation is triggered, and (b) the moment the new
flow rules have been successfully submitted to the FlowRuleService. The difference between these
timestamps represents the system’s reaction time.
5.3
Success Criteria Table
To ensure an objective evaluation, the project’s success will be judged against the following predefined,
quantitative criteria. The project will be considered successful if the adaptive routing application meets
or exceeds the target performance levels defined in Table 1.
Table 1: Performance Metrics and Validation Criteria
MetricScenarioBaseline (Static)
Target (Adaptive)
Success Criterion
Aggregate
ThroughputCongestion LoadExpected: ∼10 Mbps Expected: >15 Mbps Achieve at least a 50%
increase
in
aggregate
throughput.
End-to-End
tencyLa- Congestion LoadExpected: >100 msExpected: <50 msMaintain latency at less
than 50% of the baseline’s
latency.
Expected: >5%Expected: <1%Achieve a packet loss rate of
less than 1%.
Expected: <500 msDemonstrate a rerouting
time of under 500 ms.
Packet Loss RateCongestion Load
Rerouting TimeCongestion Trig- N/A
ger
The establishment of this formal success criteria table is of paramount importance. It transforms the
project from a purely technical exercise into a results-oriented engineering endeavor. Without such objec-
tive criteria, ”success” becomes a subjective and debatable term. This table defines specific, measurable
KPIs that are captured using standard, well-understood tools like iperf and ping.[38] It establishes a
clear baseline for comparison (the static routing case) and, most critically, sets quantitative, falsifiable
targets (e.g., ”¿50% increase in throughput”). This level of rigor forces the development process to remain
focused on delivering tangible performance benefits and provides all stakeholders with an unambiguous,
data-driven method for evaluating the project’s final outcome. It eliminates ambiguity and ensures the
validation is both meaningful and conclusive.
6
Project Execution Plan
A structured execution plan is necessary to ensure all objectives are met within the specified four-week
timeframe. The plan is organized into a work breakdown structure with clear weekly phases, deliverables,
and a proactive risk assessment.
6.1
Work Breakdown Structure
The project is logically divided into four distinct phases, with each phase corresponding to one week
of focused effort. This phased approach allows for incremental development, testing, and integration,
culminating in the final evaluation and reporting.
1. Week 1: Environment & Foundation: Focuses on setting up the complete development and
emulation environment and implementing the foundational data collection capabilities of the ap-
plication.
82. Week 2: Core Algorithm Implementation: Devoted to the design, implementation, and unit
testing of the adaptive routing algorithm, the intellectual core of the project.
3. Week 3: Integration & End-to-End Testing: Involves implementing the flow provisioning
logic and integrating all three application modules into a cohesive, functional ONOS application,
followed by initial system-level testing.
4. Week 4: Formal Evaluation & Reporting: The final week is dedicated to executing the formal
performance evaluation plan, analyzing the collected data, and authoring the final project report
and demonstration materials.
6.2
4-Week Project Timeline and Deliverables
The following table provides a detailed timeline, outlining the key tasks and corresponding deliverables
for each week of the project.
6.3
Risk Assessment and Mitigation
Proactive identification and mitigation of potential risks are crucial for timely project completion.
• Risk 1 (Technical): Misunderstanding or incorrect usage of ONOS Northbound APIs.
– Description: The ONOS APIs, particularly for flow rule programming, can be complex.
Errors in their usage could lead to significant delays and debugging challenges.
– Mitigation: A significant portion of Week 1 will be dedicated to studying the official ONOS
developer guides, API documentation, and existing application tutorials.[39, 40, 41] Building
small, isolated prototypes to test specific API calls (e.g., fetching statistics, applying a single
flow rule) will be prioritized before full-scale implementation begins.[36, 42]
• Risk 2 (Algorithmic): The routing algorithm exhibits instability.
– Description: A poorly tuned adaptive algorithm could create forwarding loops or oscillate
rapidly between two paths (”route flapping”), degrading network performance instead of im-
proving it.
– Mitigation: This risk will be addressed through both design and testing. Safeguards will
be implemented in the algorithm, such as a ”cooldown” period after a path change, during
which no further changes are permitted for that flow. Furthermore, the rigorous unit testing in
Week 2 will include specific test cases designed to provoke and identify such unstable behaviors
under simulated conditions.
• Risk 3 (Timeline): The four-week deadline is highly aggressive.
– Description: Any unforeseen technical challenges, bugs, or delays in one phase could have a
cascading effect, jeopardizing the final deadline.
– Mitigation: The project’s scope is tightly constrained to a proof-of-concept to ensure it
is achievable. The detailed weekly milestones in the project plan will be strictly monitored.
Daily or bi-daily progress checks will be conducted to identify any blockers as early as possible.
If a task is falling behind, the priority will be to resolve the issue immediately, potentially by
reallocating effort from less critical tasks within that week.
9Table 2: 4-Week Project Timeline and Deliverables
7
WeekPhase
Key TasksDeliverables
1Environment
Foundation
&- Set up development IDE (e.g.,
IntelliJ) with ONOS source code.
- Install and configure Mininet-
IP.
- Develop and test the custom
Mininet topology script.
- Implement Module 1 (Net-
work State Monitoring) and ver-
ify statistics retrieval via ONOS
logs and CLI.- A fully functional and doc-
umented development environ-
ment.
- A version-controlled codebase
initiated in Git.
- A verified Mininet topology
script.
- A working prototype of the
monitoring module.
2Core Algorithm
Implementation- Implement the modified Dijk-
stra’s algorithm (Module 2).
- Integrate the algorithm with
the monitoring module’s shared
data structures.
- Develop a comprehensive suite
of unit tests to verify the path
computation logic under various
simulated congestion scenarios.- The complete and unit-tested
routing algorithm module.
- A documented unit test suite
with high code coverage.
3Integration
End-to-End
Testing&- Implement the flow provision-
ing module (Module 3) using the
FlowRuleService.
- Integrate all three modules into
a single, deployable ONOS appli-
cation bundle (.oar file).
- Perform initial end-to-end tests
in the Mininet environment to
verify basic traffic rerouting
functionality.- A fully integrated and deploy-
able ONOS application.
- A successful demonstration of
traffic rerouting in a simple, non-
congested test case.
4Formal Evalua-
tion & Reporting- Execute the formal perfor-
mance evaluation plan as de-
tailed in Section 5.1.
- Systematically collect and or-
ganize all performance data from
both baseline and adaptive runs.
- Analyze the data, calculate
statistics, and create comparison
graphs and tables.
- Write the final, comprehen-
sive project report, detailing the
design, implementation, results,
and conclusions.- A complete set of raw and an-
alyzed performance benchmark
data.
- The final project report, includ-
ing analysis against the success
criteria.
- A presentation summarizing
the project’s goals, methods, and
findings.
References
References
[1] P. Berde, M. Gerola, J. Hart, Y. Higuchi, M. Kobayashi, T. Koide, B. Lantz, B. O’Connor, P.
Radoslavov, W. Snow, and G. Parulkar, ”ONOS: towards an open, distributed SDN OS,” in Pro-
ceedings of the third workshop on Hot topics in software defined networking (HotSDN ’14), ACM,
2014, pp. 1–6.
[2] D. Kreutz, F. M. V. Ramos, P. E. Verı́ssimo, C. E. Rothenberg, S. Azodolmolky, and S. Uhlig,
10”Software-Defined Networking: A Comprehensive Survey,” Proceedings of the IEEE, vol. 103, no. 1,
pp. 14-76, Jan. 2015.
[3] B. Lantz, B. Heller, and N. McKeown, ”A network in a laptop: rapid prototyping for software-
defined networks,” in Proceedings of the 9th ACM SIGCOMM Workshop on Hot Topics in Networks
(HotNets ’10), 2010.
[4] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wanderer, J. Zhou, M.
Zhu, et al., ”B4: Experience with a globally-deployed software defined WAN,” in ACM SIGCOMM
Computer Communication Review, vol. 43, no. 4, pp. 3-14, 2013.
[5] A. R. Curtis, J. C. Mogul, J. Tourrilhes, P. Yalagandula, P. Sharma, and S. Banerjee, ”DevoFlow:
scaling flow management for high-performance networks,” in ACM SIGCOMM Computer Commu-
nication Review, vol. 41, no. 4, pp. 254-265, 2011.
[6] ONOS. ONOS Developer Guide. Open Networking Foundation. Available:
onosproject.org/display/ONOS/Developer+Guide
https://wiki.
[7] A. H. A. S. T. M. Chowdhury and R. Boutaba, ”A survey of network virtualization,” Computer
Networks, vol. 54, no. 5, pp. 862-876, 2010.
[8] S. Scott-Hayward, S. Natarajan, and S. Sezer, ”A Survey of Security in Software Defined Networks,”
IEEE Communications Surveys & Tutorials, vol. 18, no. 1, pp. 623-654, Firstquarter 2016.
[9] A. Dixit, F. Hao, S. Mukherjee, T. V. Lakshman, and R. Kompella, ”Towards an elastic distributed
SDN controller,” in Proceedings of the second ACM SIGCOMM workshop on Hot topics in software
defined networking (HotSDN ’13), 2013, pp. 7-12.
[10] S. H. Yeganeh and Y. Ganjali, ”Kandoo: a framework for efficient and scalable offloading of con-
trol applications,” in Proceedings of the first workshop on Hot topics in software defined networks
(HotSDN ’12), 2012, pp. 19-24.
11
